from typing import List
import numpy as np
from math import inf
from tqdm import trange
import tables as tb
import os
import numba as nb
from tqdm import trange, tqdm
import dask
from concurrent.futures import ProcessPoolExecutor
from scipy import sparse
from phys_tools import utils
import json
from glob import glob


class PatternToNeuroAlignerDatFile:
    """
    This aligns frames TODO:write this doc!!!
    """
    def __init__(self, record_path, meta_path, pattern_paths):


        self._fs = self._extract_fs(meta_path)
        self._start_files, self._start_groups = self._parse_messages(record_path)
        # load frames
        with tb.open_file(meta_path) as f:
            self._pulsetimes = f.root.Events.dmd_frames.read()
        self.framedata = self._index_pulses_multi(pattern_paths)



    @staticmethod
    def _extract_fs(meta_path):
        with tb.open_file(meta_path, 'r') as f:
            fs = f.get_node_attr('/', 'acquisition_frequency_hz')
        return fs

    def _parse_messages(self, record_path):
        """
        Parse messages from openephys v4.3 flat binary recording scheme, which is totally overkill, btw.

        :param record_path: path to the directory containing "sync-messages.txt" and "events/".
        :return tuple of run starts, group starts
        """
        msgpath = os.path.join(record_path, "experiment1/recording1")
        if not os.path.exists(msgpath):
            raise FileNotFoundError("messages not found at {}".format(msgpath))
            # todo: this is some special sauce here for openephys, and it might be good to abstract this away.

        eventspath = os.path.join(msgpath, 'events/Network_Events-102.0/TEXT_group_1')

        syncpath = os.path.join(msgpath, 'sync_messages.txt')
        with open(syncpath, 'r') as f:
            synctxt = f.read()
        syncpattern = 'start time:'
        syncstart = synctxt.find(syncpattern) + len(syncpattern)
        synctime, _ = synctxt[syncstart:].split('@')
        synctime = int(synctime)

        lines = np.load(os.path.join(eventspath, "text.npy"))
        times = np.load(os.path.join(eventspath, "timestamps.npy"))
        times -= synctime
        presentation_starts = []
        uuid_starts = []

        for line_b, time in zip(lines, times):
            line = line_b.decode()
            p_name = utils.random_patterns.parse_presentation_sep(line)
            if p_name:
                presentation_starts.append((time, p_name))
            else:
                u_start = utils.random_patterns._parse_uuid_sep(line)
                if u_start:
                    uuid_starts.append((time, u_start))
        return uuid_starts, presentation_starts

    def _index_pulses_multi(self, pattern_files: List[str]) -> List[dict]:
        """
        This is used to assign each pulse in the dmd_frames array to a specific leaf (sequence) in the pattern
        hdf5 file and to a specific frame within this array.

        It assumes sequentiality of pulses and frames/sequences for alignment and is not self correcting if this
        sequentiality is violated. However, it is error detecting through the use of sync pulse width modulation
        that varies between different sequences. The expected pulsewidth is encoded in the pattern hdf5 file and
        is checked versus the recorded pulse width.

        In the future, it would be useful to add self healing features to this. ie if a pulse or an image array
        are missing, the function should be able to recover from this. This adds a layer of complexity that would
        take at least a day for me to implement and verify and would probably require the use of a more complex
        framework (ie a Sequence class for each array with built in pulse acceptance or rejection checker and
        integrity verification methods).

        returns:
        * a list of strings that can be used to to get to specific sequence nodes in the hdf5 file.
        * an array of indices for each pulse corresponding to the leaf (sequence) name in the above list. This index
        only moves at the start of a new sequence - many (ie 250) pulses may correspond to frames within the same
        seqence leaf.
        * an array of indices for each pulse corresponding to the index of the frame in the sequence for each pulse
        this index moves fastest - each pulse corresponds to a different frame in the sequence.


        :param group_times: list of tuple (start_sample: group_id_string) ie (34234, 'aaa'
        :param pattern_file: path to hdf5 file generated by stimulus generator.
        :param pulse_times: N-by-2 array where each row is pulse on and off times in samples.
        :param fs: sampling frequency of ephys acquision system in Hz. default is 30000
        """

        if type(pattern_files) is str:  #wrap in string
            pattern_files = [pattern_files]

        files_by_uuid = {}
        start_times_by_uuid = {}
        start_times = []
        end_times_by_uuid = {}
        uuids_in_order = []

        # enumerate startimes
        for t, uuid in self._start_files:
            start_times_by_uuid[uuid] = t
            uuids_in_order.append(uuid)
            start_times.append(t)

        # enumerate endtimes
        for i in range(len(uuids_in_order) - 1):
            uuid = uuids_in_order[i]
            endtime = start_times[i + 1]
            end_times_by_uuid[uuid] = endtime
        # because we don't know the end time, this will catch all remaining pulses and grouptimes
        end_times_by_uuid[uuids_in_order[-1]] = -1

        # get the uuids for each file specified
        for fn in pattern_files:
            with tb.open_file(fn, 'r') as f:
                titlestr = f.root._v_title
            _, uuid = titlestr.split(':')
            files_by_uuid[uuid] = fn

        assert len(start_times_by_uuid) == len(files_by_uuid)
        # todo: all override this to be overridden if you don't want to process all the uuids, for example.

        pp = ProcessPoolExecutor()
        tasks = []
        for uuid in uuids_in_order:
            start = start_times_by_uuid[uuid]
            end = end_times_by_uuid[uuid]
            pulses = self._get_pulse_subset(start, end)
            groups = self._get_grouptimes_subset(self._start_groups, start, end)
            fn = files_by_uuid[uuid]
            tasks.append(pp.submit(self.index_pulses, groups, fn, pulses, self._fs))
        frame_data_by_file = [x.result() for x in tasks]
        return frame_data_by_file

    @staticmethod
    def index_pulses(group_times: List[tuple], pattern_filename: str, pulse_times: np.ndarray,
                     fs=30000):
        """
        This is used to assign each pulse in the dmd_frames array to a specific leaf (sequence) in the pattern
        hdf5 file and to a specific frame within this array.

        It assumes sequentiality of pulses and frames/sequences for alignment and is not self correcting if this
        sequentiality is violated. However, it is error detecting through the use of sync pulse width modulation
        that varies between different sequences. The expected pulsewidth is encoded in the pattern hdf5 file and
        is checked versus the recorded pulse width.

        In the future, it would be useful to add self healing features to this. ie if a pulse or an image array
        are missing, the function should be able to recover from this. This adds a layer of complexity that would
        take at least a day for me to implement and verify and would probably require the use of a more complex
        framework (ie a Sequence class for each array with built in pulse acceptance or rejection checker and
        integrity verification methods).

        returns:
        * a list of strings that can be used to to get to specific sequence nodes in the hdf5 file.
        * an array of indices for each pulse corresponding to the leaf (sequence) name in the above list. This index
        only moves at the start of a new sequence - many (ie 250) pulses may correspond to frames within the same
        seqence leaf.
        * an array of indices for each pulse corresponding to the index of the frame in the sequence for each pulse
        this index moves fastest - each pulse corresponds to a different frame in the sequence.


        :param group_times: list of tuple (start_sample: group_id_string) ie (34234, 'aaa'
        :param pattern_file: path to hdf5 file generated by stimulus generator.
        :param pulse_times: N-by-2 array where each row is pulse on and off times in samples.
        :param fs: sampling frequency of ephys acquision system in Hz. default is 30000
        """

        n_pulses = len(pulse_times)
        leaf_names = []  # list of strings useful to get a sequence node using tb.File.get_node()
        leaf_indices = np.zeros(n_pulses, dtype='uint16')  # an index (to leafnames) for every pulse
        frame_indices = np.zeros_like(leaf_indices)  # an index to the leaf for every pulse
        us_per_samp = 1. / (fs * 1e-6)  # ~33.33 for 30 kHz. THIS is also the unit of error we need to accomodate...
        sync_error_allowed = us_per_samp * 1.1  # error to allow for quantization error of sync signal.

        pulse_widths_rec_samps = np.diff(pulse_times)[:, 0]
        pulse_widths_rec_us = us_per_samp * pulse_widths_rec_samps

        current_group = -1  # careful, -1 can index...
        current_leaf = -1
        current_leaf_syncwidth = -1
        group_start_times = [x[0] for x in group_times]  # in samples
        next_group_starttime = group_start_times[current_group + 1]
        leaf_idx = -1  # running count of where we are in the leaf_names list. will be iterated in first loop
        frames_in_leaf = -2
        frame_count_leaf = -1
        with tb.open_file(pattern_filename, 'r') as pattern_file:
            for i in range(len(pulse_times) - 1):
                # last pulse time is somehow corrupted. getting rid of one frame is not going to hurt.
                pulsetime = pulse_times[i, 0]
                pulsewidth = pulse_widths_rec_us[i]
                # todo: handle pulses that occur before the recording start time? This could happen if we're not
                # careful and start a recording prior to
                if pulsetime >= next_group_starttime:
                    current_group += 1
                    # force move to next leaf...
                    current_leaf = -1
                    current_leaf_syncwidth = -2 * us_per_samp
                    frames_in_leaf = 0
                    frame_count_leaf = 0
                    groupname = group_times[current_group][1]
                    groupnodepath = '/patterns/{}'.format(groupname)  # ie /patterns/aab
                    group = pattern_file.get_node(groupnodepath)
                    # n_leafs = group._v_nchildren
                    if current_group < len(group_start_times) - 1:  # we're looking for passing the next start time.
                        next_group_starttime = group_start_times[current_group + 1]
                    else:
                        next_group_starttime = inf

                # this is forced true on switching to a new group.
                # it is NOT true if we have a pulse that is not accounted for in a sequence at the beginning of the record.
                if frame_count_leaf == frames_in_leaf:
                    current_leaf += 1
                    frame_count_leaf = 0
                    leafpath = "{}/{:06n}".format(groupnodepath, current_leaf)
                    try:
                        leaf = pattern_file.get_node(leafpath)
                    except tb.NoSuchNodeError:
                        # there is a problem with the stimulus generator: if it shuts down with ctrl-c, the saving of the last
                        # uploaded sequence is not guaranteed. So we'll have unaccounted for pulses that we need to ignore.
                        print(
                            'Warning no node found at {}, {} of {} pulses are accounted for. Returning {} pulses.'.format(
                                leafpath, i, n_pulses, n_pulses))
                        break  # stop indexing future pulses, as we're not going to find them...
                        # todo: we maybe should be able to handle a missing leaf and move on to the next group of pulses.
                    frames_in_leaf, _, _ = leaf.shape
                    current_leaf_syncwidth = int(leaf.get_attr('sync_pulse_dur_us'))
                    leaf_names.append(leafpath)
                    leaf_idx += 1
                d = np.abs(current_leaf_syncwidth - pulsewidth)
                if d > sync_error_allowed:
                    raise ValueError('pulsewidth and syncwidth mismatch!!')

                leaf_indices[i] = leaf_idx
                frame_indices[i] = frame_count_leaf
                frame_count_leaf += 1  # not actually in place assignment, so won't change arrays.
        # return only
        return dict(
            pattern_filename=os.path.abspath(pattern_file.filename),
            leaf_names=leaf_names,
            leaf_indices=leaf_indices[:i],  # crop arrays to the last pulse accounted for
            frame_indices=frame_indices[:i],
            frame_times=pulse_times[:i, 0],
        )

    @staticmethod
    def _get_grouptimes_subset(grouptimes, start, end) -> list:
        """
        Returns the subset of grouptimes that fall between the start and end values.
        """

        subset = []
        if end < 0:
            end = inf  # get all the rest of the groups.
        for t, v in grouptimes:
            if t >= start and not t > end:
                subset.append((t, v))
        return subset

    def _get_pulse_subset(self, start, end):
        """
        :param pulsetimes: N x 2 array of pulse starts and ends
        :param start: start times
        :param end: end times
        :return:
        """

        pulse_starts = self._pulsetimes[:, 0]
        i_st = np.searchsorted(pulse_starts, start)
        if end > 0:
            i_nd = np.searchsorted(pulse_starts, end)
        else:
            i_nd = None  # this returns all values including the value at the -1 position.
        return self._pulsetimes[i_st:i_nd, :]

#TODO: check that you can load subsets of patternfiles

class PatternToNeuroAlignerOephysFile(PatternToNeuroAlignerDatFile):

    def _parse_messages(self, record_dir) -> tuple:
        """ Extracts the times and IDs for events that were sent from random pattern stimulus generator.

        returns: tuple (run starts, presentation sequence starts)
        run starts: tuple(start time, run uuid (ie '2bd583a9-aa52-4854-9554-5ae815565674'))
        presentation sequence starts = tuple(start time, sequence id (ie 'aaa'))
        """

        with open(os.path.join(record_dir, 'messages.events'), 'r') as f:
            txt = f.read()
        lines = txt.splitlines()

        # the start of the recording is not 0 in message time. Instead, openephys uses an internal
        # processor time that starts probably when the acquisition is started (as opposed to when
        # the save file is started). So we have to extract this starttime and subtract it from the
        # message times that we are extracting
        start_str = "start time: "
        startfound = -1
        ln = 0
        while startfound < 0 and ln < len(lines):
            line = lines[ln]
            startfound = line.find(start_str)
            ln += 1
        if startfound < 0:
            errst = 'No "start time: " pattern found in {} message file.'.format(record_dir)
            raise ValueError(errst)
        start_samp = line[(startfound + len(start_str)):]
        start_samp, fs = start_samp.split('@')
        start_samp = int(start_samp)

        presentation_starts = []
        uuid_starts = []

        for line in lines:
            p_start = utils.random_patterns.parse_presentation(line, start_samp)
            if p_start:
                presentation_starts.append(p_start)
            u_start = utils.random_patterns.parse_uuid(line, start_samp)
            if u_start:
                uuid_starts.append(u_start)
            return uuid_starts, presentation_starts


class PatternLoaderFullFrame:
    """
    Loads frames that are scaled representations of the DMD and represents them as a N_fr-by-N_px matrix.
    """
    def __init__(self, aligner: PatternToNeuroAlignerDatFile, mask_path=''):
        if mask_path:  # mask file can be specified for older recordings, new recordings have this embedded in pattern files.
            self._mask = np.load(mask_path)
        else:
            self._mask = self._extract_mask(aligner)
        self.scale = self._extract_scale(aligner)

        self.mask = utils.random_patterns.find_unmasked_px(self._mask, self.scale)

        self._n_frames = sum([len(x['frame_times']) for x in aligner.framedata])

        self.frame_times, self.frames = self._extract_frames(aligner)

    def _extract_scale(self, aligner):
        """

        :param aligner:
        :return:
        """
        fd = aligner.framedata[0]
        fn = fd['pattern_filename']
        with tb.open_file(fn, 'r') as f:
            iterer = f.walk_nodes('/patterns', 'CArray')
            node = iterer.__next__()  # type: tb.CArray
            scale = node.get_attr('image_scale')
        return scale

    def _extract_mask(self, aligner):
        """

        :param aligner:
        :return:
        """
        fd = aligner.framedata[0]
        fn = fd['pattern_filename']
        with tb.open_file(fn, 'r') as f:
            mask = f.get_node('/pixel_mask').read()
        return mask

    def _extract_frames(self, aligner):
        """

        :param aligner:
        :return:
        """
        i_global = 0  # counter for all frames across files in the framedata list.
        images = np.zeros((self._n_frames, self.mask.sum()), 'bool')
        times = np.zeros(self._n_frames, 'uint32')

        for fd_item in tqdm(aligner.framedata):
            filename = fd_item['pattern_filename']
            nframes = len(fd_item['leaf_indices'])
            leaf_ids = fd_item['leaf_indices']
            leafnames = fd_item['leaf_names']
            frametimes = fd_item['frame_times']
            frame_ids = fd_item['frame_indices']
            last_leafname = ''

            with tb.open_file(filename, 'r') as f:
                for i in range(nframes):
                    leaf_id = leaf_ids[i]
                    leafname = leafnames[leaf_id]
                    if leafname != last_leafname:
                        frames = f.get_node(leafname).read()[:, self.mask]
                        last_leafname = leafname
                    frame_id = frame_ids[i]  # relate the index of the framedata to the stored array index
                    frame = frames[frame_id, :]
                    images[i_global,:] = frame
                    times[i_global] = frametimes[i]
                    i_global += 1
        return times, images


class FrameSaverSparse:
    def __init__(self, frame_loader: PatternLoaderFullFrame, save_prefix='', save_path=''):
        """

        :param savepath:
        :param frame_loader:
        """
        frames = frame_loader.frames
        frametimes = frame_loader.frame_times
        scale = frame_loader.scale
        mask = frame_loader.mask

        metadict = {
            'scale': int(scale)
        }

        self.paths = self._gen_paths(save_path, save_prefix)
        self._save_times(frametimes)
        self._save_mask(mask)
        self._save_meta(metadict)
        self._save_frames(frames)

    def _gen_paths(self, root_path, prefix):

        if prefix:
            prefix = prefix + '_'

        timepath = os.path.join(root_path, '{}frametimes'.format(prefix))
        framepath = os.path.join(root_path, '{}frames'.format(prefix))
        maskpath = os.path.join(root_path, '{}mask'.format(prefix))
        meta = os.path.join(root_path, '{}info.json')
        return {
            "time": timepath,
            "frames": framepath,
            "mask": maskpath,
            "meta": meta,
        }

    def _save_meta(self, metadict):
        with open(self.paths['meta'], 'w') as f:
            json.dump(metadict, f)

    def _save_times(self, times_array):
        np.save(self.paths['time'], times_array)

    def _save_mask(self, mask_array):
        np.save(self.paths['mask'], mask_array)

    def _save_frames(self, frames_dense):
        tosave = sparse.csr_matrix(frames_dense)
        sparse.save_npz(self.paths['frames'], tosave)

    def _make_framestore(self, frames_dense):
        return



def pipeline(record_path, pattern_prefix, meta_path=None, save_prefix='', save_path='', mask_path=''):

    pattern_paths = glob(pattern_prefix)
    pattern_paths.sort()
    print('aligning frames...', end='')
    aligner = PatternToNeuroAlignerDatFile(record_path, meta_path, pattern_paths)
    print('loading frames...', end='')
    loader = PatternLoaderFullFrame(aligner, mask_path)
    print('saving frames...', end='')
    saver = FrameSaverSparse(loader, save_prefix, save_path)
    print('complete.')
    return

